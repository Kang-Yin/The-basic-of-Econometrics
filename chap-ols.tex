\chapter{最小二乘法}
\label{chap:ols}

\section{最小二乘法的历史}
最小二乘法(ordinary least square)是计量经济学中最为重要也是最为常用的模型估计方法，该方法因为其估计原理直观、求解过程简单、
估计结果性质优良等特征而广受欢迎。对于最小二乘法的出现，很多人认为是高斯在19世纪初提出的，当时为了分析天体运行轨迹，需要有
一种方法来处理行星的理论运行轨迹和实际观测轨迹的偏差。当然，对于这样一种在数学上极为“简单”的处理方法，高斯并未觉得提出
最小二乘法有多么了不起，直到勒让德在一篇论文中正式提出最小二乘法后，高斯才在其与友人的信函中说他多年前就已经使用该方法。
出于对高斯学术品行的认可，尽管他未正式发表他的这一成果，但后来的学者还是都认为，是高斯最先发现了最小二乘法。

现在，最小二乘法已经成为计量经济学中估计模型参数最主要的三类方法之一，任意一本计量经济学的教科书，都会从最小二乘法开始介绍，
它也成为每一个计量经济学研究人员工具箱中必备工具。同时，对最小二乘法的学习也是我们进一步掌握相对复杂的参数估计方法的基础。

\section{回归与最小二乘法}
虽然最小二乘法的出现要早于“回归”一词，但是前者现已归属于回归中一类估计方法。因此在讨论最小二乘法之前，需要简单介绍回归的
基本概念及其思想。一般意义上的回归或回归函数是指，对于被解释变量$Y$以及解释变量$X=(X_2,\cdots,X_k)$，称$E(Y|X)$是$Y$关于
$X$的回归。显然，这一条件期望又可以表示$Y$关于$X$的函数，即$E(Y|X)=f(X)$。如果$f(\cdot)$为线性函数，则$Y$关于$X$的回归为
线性回归，如果$f(\cdot)$为非线性函数，则$Y$关于$X$的回归为非线性回归。无论是线性回归还是非线性回归，其模型中的参数均可利用
最小二乘法进行求解，只是在求解过程上难易程度不同。当然，如果$f(\cdot)$没有确定的函数形式，则需要用到非参数回归的方法来拟合
$Y$与$X$之间关系，核估计是解决这一类问题的常用方法，这些内容不属于本章范畴，故不再展开。

\subsection{线性回归模型}
最为简单常见的回归模型为线性回归，具体形式如下：
\begin{equation}
  Y_i = \beta_1 + \beta_2 X_{2i} + \cdots + \beta_k X_{ki} + \varepsilon_i \quad i = 1,\cdots,n
\end{equation}
其中$\beta$为模型系数，或称待估参数；$\varepsilon$为模型中引入的随机扰动项；$n$为样本容量。一个更为简化的矩阵版本如下：
\begin{equation}
  \mathbf{Y} = \mathbf{X}\mathbf{\beta} + \mathbf{\varepsilon}
\end{equation}
其中$\mathbf{Y} = (Y_1,\cdots,Y_n)$，$\mathbf{X} = (1,X_2,\cdots,X_k)$，这里$\mathbf{1}$一个元素全为1的n维列向量，$X_2$
，...，$X_k$是各个解释变量的n次观测所组成的列向量。

回归模型中的参数估计，就是要找到一个最具有代表性的经验方程$\widehat{f(X)}$去反映总体回归模型$f(X)$的特征。什么样的经验方程才
具有代表性呢？这取决于建模者所确定的标准。




\section{经典假设}
从求解的角度看，最小二乘法的实施并不依赖过多的假定，只需样本个数超过模型中待估参数的个数并且所有样本点的横坐标不完全相同，
最小二乘法即可求解出回归模型中的参数估计值。

